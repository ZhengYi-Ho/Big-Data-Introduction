{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "Load classes and weather data\n",
    "\n",
    "Run the cell to:\n",
    "-load the SQLContext, \n",
    "-create instance of SQLContext and\n",
    "-read the weather data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.load('file:///home/cloudera/Downloads/big-data-4/daily_weather.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2:\n",
    "Print the summary statistics for ALL COLUMNS using describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just look at the statistics for the air temp at 9am:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1090|\n",
      "|   mean| 64.93300141287075|\n",
      "| stddev|11.175514003175877|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['air_temp_9am']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the total number of rows in the DataFrame is 1095 while the number of rows in air_temp_9am is 1090.\n",
    "\n",
    "This indicates that there are missing values in air_temp_9am\n",
    "\n",
    "The following command shows the total number of rows in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3:\n",
    "Remove missing values\n",
    "\n",
    "We can drop all the rows missing a value in any calling using na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "removeAllDF = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the summary statistics for air_temp_9am with the MISSING VALUE DROPPED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1064|\n",
      "|   mean| 65.02260949558739|\n",
      "| stddev|11.168033449415699|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "removeAllDF.describe(['air_temp_9am']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to compare the summary statistics before and after dropping the missing value\n",
    "\n",
    "We can see that the mean and standard deviation is close to the original values, for mean is 64.933 vs. 65.022 and standard deviation is 11.175 vs. 11.168\n",
    "\n",
    "Also you can notice that the count is 1064, which means that 1095-1064 = 31 rows dropped.\n",
    "\n",
    "We can see this agrees with the total number of rows in the new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1064"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeAllDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far the process goes like:\n",
    "\n",
    "Read the file into DataFrame -> \n",
    "Print summary statistics ->\n",
    "Look at statistics for air_temp_9am ->\n",
    "Remove missing values ->\n",
    "Look at statistics for air_temp_9am after dropping->\n",
    "Look at number of rows for DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4:\n",
    "Impute missing values\n",
    "\n",
    "Instead of removing rows containing missing values,\n",
    "let's replace the values with the mean value for that column.\n",
    "\n",
    "FIRST, we'll load the avg function and make a COPY of the original DataFrame for future comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "imputeDF = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll iterate through each column in the DataFrame:\n",
    "\n",
    "compute the mean value fot that COLUMN and replace any MISSING VALUES in that column with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 545.0018796992481\n",
      "air_pressure_9am 918.9031798641055\n",
      "air_temp_9am 65.02260949558739\n",
      "avg_wind_direction_9am 142.30675564934032\n",
      "avg_wind_speed_9am 5.485793050713691\n",
      "max_wind_direction_9am 148.48042413321312\n",
      "max_wind_speed_9am 6.9997136588756925\n",
      "rain_accumulation_9am 0.18202347650615522\n",
      "rain_duration_9am 266.3936973996038\n",
      "relative_humidity_9am 34.07743985327712\n",
      "relative_humidity_3pm 35.14838093290537\n"
     ]
    }
   ],
   "source": [
    "for x in imputeDF.columns:\n",
    "    meanValue = removeAllDF.agg(avg(x)).first()[0]\n",
    "    print(x, meanValue)\n",
    "    imputeDF = imputeDF.na.fill(meanValue, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agg() function performs an aggregate calculation on the DataFrame and avg(x) specifies to compute the mean on column x.\n",
    "\n",
    "The agg() function returns a DataFrame, first() returns the FIRST row, and [0] gets the first value.\n",
    "\n",
    "The LAST line of the code uses na.fill() to replace the missing values with the mean value(FIRST ARGUEMENT) in column x(SECOND ARGUEMENT).\n",
    "\n",
    "The output of executing this cell prints the mean values for each column and we can see the mean value for air_temp_9am is the same mean when we remove all the missing values in step 4, i.e., 65.022\n",
    "\n",
    "`Either we remove the missing value or replace them with mean, we get the same result`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 5:\n",
    "Print imputed data summary statistics\n",
    "\n",
    "Let's call describe() to show the summary statistics for the ORIGINAL and IMPUTED air_temp_9am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1090|\n",
      "|   mean| 64.93300141287075|\n",
      "| stddev|11.175514003175877|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1095|\n",
      "|   mean| 64.93341058219822|\n",
      "| stddev|11.149948199920226|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['air_temp_9am']).show()\n",
    "imputeDF.describe(['air_temp_9am']).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
